{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW8RxzU6-I7I",
        "outputId": "c9c94011-36b1-4a4f-93ad-1f75d61f7532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu working\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"cuda working\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"cpu working\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 load the dataset\n",
        "#2 basic prprocessing with the data\n",
        "#3 Training process\n",
        "#4 creat the model\n",
        "#5 forward propagation\n",
        "#6 loss calculation\n",
        "#7 backward propagation\n",
        "#8 paramter update\n",
        "#9 Model evaluation"
      ],
      "metadata": {
        "id": "HTZOu7vz-Tlh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so the very first creat the class for nn\n",
        "\n",
        "class NeuralNetwrok(nn.Module):\n",
        "  def __init__(self,features):    #constructor for the class to initalize the value\n",
        "    super().__init__()                  #call the neural netork functions\n",
        "    self.linear = nn.Linear(features,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    #forward propagation\n",
        "  def forward(self,x):\n",
        "    x = self.linear(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UFW1396z-4cD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1 creat a dataset\n",
        "features = torch.rand(10,5)\n",
        "\n",
        "#creat the  model\n",
        "model = NeuralNetwrok(features.shape[1])"
      ],
      "metadata": {
        "id": "YWBHozu4BO9x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6KY6TVNBoSE",
        "outputId": "a363cb8b-09a7-4619-a33d-d77f03c3676f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(features).shape #to get the y pred for every rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71KCiB60BtWS",
        "outputId": "35f2fdad-df40-48e8-fbee-5ee8871f1774"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH-b2s72B6qQ",
        "outputId": "b9169ef3-5bfb-4aba-b59d-058fe9a2b7cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0726, -0.4170, -0.1295, -0.0027,  0.4347]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBx82kJxC5LC",
        "outputId": "6fdc736e-b659-4312-a680-503c4a2fa5e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0634], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prx6ljBUDSWg",
        "outputId": "47580b02-62f7-4b68-c653-f2dc9475f2b1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model,input_size=(10,5)) #5 inputs weights and one bais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcG_XV4ODAcH",
        "outputId": "80d976d7-eb0c-4ec8-e015-b87dd2314ef4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "NeuralNetwrok                            [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 1]                   6\n",
              "├─Sigmoid: 1-2                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define data for the class #ANSWER SHOULD BE binary\n",
        "x_train = torch.rand(10,5)\n",
        "y_train = torch.randint(0,2,(10,1))\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5O6hWDKIHdu",
        "outputId": "ef572404-bdfb-4cf4-c176-0204649bc2d4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now make with hidden layers\n",
        "input_shape = 5\n",
        "hidden_node = 3\n",
        "ouput_Node = 1\n",
        "class Neural(nn.Module):\n",
        "\n",
        "  def __init__(self,input_shape,hidden_node,ouput_Node):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(  #sequential container\n",
        "       nn.Linear(input_shape,hidden_node),\n",
        "       nn.ReLU(),\n",
        "       nn.Linear(hidden_node,ouput_Node),\n",
        "       nn.Sigmoid())\n",
        "\n",
        "  #forward propagation\n",
        "  def forward(self,features):\n",
        "    return self.sequential(features)\n",
        "\n",
        "  def lossFunction(self,y_pred,y):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred,epsilon,1-epsilon)\n",
        "    loss = -(y_train * torch.log(y_pred) + (1-y_train) * torch.log(1-y_pred)).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "2kYQC3wCDQun"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learning rate\n",
        "lr = 0.01\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "0tQBT0h7IjBF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Neural(x_train.shape[1],hidden_node=3,ouput_Node=1)\n",
        "\n",
        "#define the loop\n",
        "for epoch in range(epochs):\n",
        "    y_pred = model1(x_train)\n",
        "    loss = model1.lossFunction(y_pred,y_train)\n",
        "\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model1.sequential[0].weight -= lr * model1.sequential[0].weight.grad\n",
        "      model1.sequential[0].bias -= lr * model1.sequential[0].bias.grad\n",
        "\n",
        "    #zero gradient the wiegts\n",
        "    model1.sequential[0].weight.grad.zero_()\n",
        "    model1.sequential[0].bias.grad.zero_()\n",
        "\n",
        "    #print loss in each epochs\n",
        "    print(f\"epoch,{epoch + 1}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Reb9GjIojb",
        "outputId": "135eb0fc-4f43-4994-d374-4988600e49d0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch,1, loss: 0.687419056892395\n",
            "epoch,2, loss: 0.6873587965965271\n",
            "epoch,3, loss: 0.6872986555099487\n",
            "epoch,4, loss: 0.6872385740280151\n",
            "epoch,5, loss: 0.6871785521507263\n",
            "epoch,6, loss: 0.6871185898780823\n",
            "epoch,7, loss: 0.6870585680007935\n",
            "epoch,8, loss: 0.6869987845420837\n",
            "epoch,9, loss: 0.6869390606880188\n",
            "epoch,10, loss: 0.6868792772293091\n",
            "epoch,11, loss: 0.6868196725845337\n",
            "epoch,12, loss: 0.6867600083351135\n",
            "epoch,13, loss: 0.6867004632949829\n",
            "epoch,14, loss: 0.6866409182548523\n",
            "epoch,15, loss: 0.6865814924240112\n",
            "epoch,16, loss: 0.6865220665931702\n",
            "epoch,17, loss: 0.6864627599716187\n",
            "epoch,18, loss: 0.6864035129547119\n",
            "epoch,19, loss: 0.6863442659378052\n",
            "epoch,20, loss: 0.6862851977348328\n",
            "epoch,21, loss: 0.6862260699272156\n",
            "epoch,22, loss: 0.6861670613288879\n",
            "epoch,23, loss: 0.6861081719398499\n",
            "epoch,24, loss: 0.686049222946167\n",
            "epoch,25, loss: 0.6859903335571289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now creat the fake dataset for the nn module\n",
        "features = torch.rand(10,5)\n",
        "model1 = Neural(input_shape,hidden_node,ouput_Node)"
      ],
      "metadata": {
        "id": "nTTrtVYTE373"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now will use otimizer of inbuilt and loss function\n",
        "#Now make with hidden layers\n",
        "input_shape = 5\n",
        "hidden_node = 3\n",
        "ouput_Node = 1\n",
        "loss_function = nn.BCELoss()\n",
        "class Neural(nn.Module):\n",
        "\n",
        "  def __init__(self,input_shape,hidden_node,ouput_Node):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(  #sequential container\n",
        "       nn.Linear(input_shape,hidden_node),\n",
        "       nn.ReLU(),\n",
        "       nn.Linear(hidden_node,ouput_Node),\n",
        "       nn.Sigmoid())\n",
        "\n",
        "  #forward propagation\n",
        "  def forward(self,features):\n",
        "    return self.sequential(features)"
      ],
      "metadata": {
        "id": "sezMW1kDFO-y"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(loss_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "A12F0UhCMmXN",
        "outputId": "dbb1cb2f-5964-4132-b14f-dc1348711a6d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.loss.BCELoss"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.loss.BCELoss</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py</a>Creates a criterion that measures the Binary Cross Entropy between the target and\n",
              "the input probabilities:\n",
              "\n",
              "The unreduced (i.e. with :attr:`reduction` set to ``&#x27;none&#x27;``) loss can be described as:\n",
              "\n",
              ".. math::\n",
              "    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
              "    l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
              "\n",
              "where :math:`N` is the batch size. If :attr:`reduction` is not ``&#x27;none&#x27;``\n",
              "(default ``&#x27;mean&#x27;``), then\n",
              "\n",
              ".. math::\n",
              "    \\ell(x, y) = \\begin{cases}\n",
              "        \\operatorname{mean}(L), &amp; \\text{if reduction} = \\text{`mean&#x27;;}\\\\\n",
              "        \\operatorname{sum}(L),  &amp; \\text{if reduction} = \\text{`sum&#x27;.}\n",
              "    \\end{cases}\n",
              "\n",
              "This is used for measuring the error of a reconstruction in for example\n",
              "an auto-encoder. Note that the targets :math:`y` should be numbers\n",
              "between 0 and 1.\n",
              "\n",
              "Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be\n",
              "mathematically undefined in the above loss equation. PyTorch chooses to set\n",
              ":math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\n",
              "However, an infinite term in the loss equation is not desirable for several reasons.\n",
              "\n",
              "For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\n",
              "multiplying 0 with infinity. Secondly, if we have an infinite loss value, then\n",
              "we would also have an infinite term in our gradient, since\n",
              ":math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\n",
              "This would make BCELoss&#x27;s backward method nonlinear with respect to :math:`x_n`,\n",
              "and using it for things like linear regression would not be straight-forward.\n",
              "\n",
              "Our solution is that BCELoss clamps its log function outputs to be greater than\n",
              "or equal to -100. This way, we can always have a finite loss value and a linear\n",
              "backward method.\n",
              "\n",
              "\n",
              "Args:\n",
              "    weight (Tensor, optional): a manual rescaling weight given to the loss\n",
              "        of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
              "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
              "        the losses are averaged over each loss element in the batch. Note that for\n",
              "        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
              "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
              "        when :attr:`reduce` is ``False``. Default: ``True``\n",
              "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
              "        losses are averaged or summed over observations for each minibatch depending\n",
              "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
              "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
              "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
              "        ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,\n",
              "        ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of\n",
              "        elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`\n",
              "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
              "        specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``\n",
              "\n",
              "Shape:\n",
              "    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
              "    - Target: :math:`(*)`, same shape as the input.\n",
              "    - Output: scalar. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`, same\n",
              "      shape as input.\n",
              "\n",
              "Examples::\n",
              "\n",
              "    &gt;&gt;&gt; m = nn.Sigmoid()\n",
              "    &gt;&gt;&gt; loss = nn.BCELoss()\n",
              "    &gt;&gt;&gt; input = torch.randn(3, 2, requires_grad=True)\n",
              "    &gt;&gt;&gt; target = torch.rand(3, 2, requires_grad=False)\n",
              "    &gt;&gt;&gt; output = loss(m(input), target)\n",
              "    &gt;&gt;&gt; output.backward()</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 611);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model = Neural(x_train.shape[1],hidden_node=3,ouput_Node=1)\n",
        "\n",
        "#define the loop\n",
        "for epoch in range(epochs):\n",
        "    y_pred = Model(x_train)\n",
        "    loss =loss_function(y_pred,y_train.float())\n",
        "\n",
        "    #backward propagation\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for param in Model.parameters():\n",
        "        param -= lr * param.grad\n",
        "\n",
        "    #zero gradient the wiegts\n",
        "    Model.zero_grad()\n",
        "\n",
        "    #print loss in each epochs\n",
        "    print(f\"epoch,{epoch + 1}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuSucVjHMEBN",
        "outputId": "b69ac824-7c37-4fa2-8dc2-96cf71cf491c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch,1, loss: 0.7355154752731323\n",
            "epoch,2, loss: 0.7355154752731323\n",
            "epoch,3, loss: 0.7355154752731323\n",
            "epoch,4, loss: 0.7355154752731323\n",
            "epoch,5, loss: 0.7355154752731323\n",
            "epoch,6, loss: 0.7355154752731323\n",
            "epoch,7, loss: 0.7355154752731323\n",
            "epoch,8, loss: 0.7355154752731323\n",
            "epoch,9, loss: 0.7355154752731323\n",
            "epoch,10, loss: 0.7355154752731323\n",
            "epoch,11, loss: 0.7355154752731323\n",
            "epoch,12, loss: 0.7355154752731323\n",
            "epoch,13, loss: 0.7355154752731323\n",
            "epoch,14, loss: 0.7355154752731323\n",
            "epoch,15, loss: 0.7355154752731323\n",
            "epoch,16, loss: 0.7355154752731323\n",
            "epoch,17, loss: 0.7355154752731323\n",
            "epoch,18, loss: 0.7355154752731323\n",
            "epoch,19, loss: 0.7355154752731323\n",
            "epoch,20, loss: 0.7355154752731323\n",
            "epoch,21, loss: 0.7355154752731323\n",
            "epoch,22, loss: 0.7355154752731323\n",
            "epoch,23, loss: 0.7355154752731323\n",
            "epoch,24, loss: 0.7355154752731323\n",
            "epoch,25, loss: 0.7355154752731323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = Model.forward(x_train)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == y_train).float().mean()\n",
        "  print(f\"accuracy: {accuracy}\") #although acc is not good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh3lpJ-qM8Gf",
        "outputId": "8e136255-6956-4e73-a98e-ba56e9157c0f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.4000000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Us67rMXUNdxo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4L9sPhhOIE5",
        "outputId": "f8891993-05f5-4706-a52b-03b2c79018cd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now built in optimizer\n",
        "#Now make with hidden layers\n",
        "input_shape = 5\n",
        "hidden_node = 3\n",
        "ouput_Node = 1\n",
        "class Neural(nn.Module):\n",
        "\n",
        "  def __init__(self,input_shape,hidden_node,ouput_Node):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(  #sequential container\n",
        "       nn.Linear(input_shape,hidden_node),\n",
        "       nn.ReLU(),\n",
        "       nn.Linear(hidden_node,ouput_Node),\n",
        "       nn.Sigmoid())\n",
        "\n",
        "  #forward propagation\n",
        "  def forward(self,features):\n",
        "    return self.sequential(features)\n",
        "\n",
        "Modle = Neural(x_train.shape[1],hidden_node=3,ouput_Node=1)\n",
        "#define builtin optimizer\n",
        "#define loss function\n",
        "optimizer = torch.optim.SGD(Modle.parameters(),lr=0.01)\n",
        "loss_function = nn.BCELoss()\n",
        "type(Modle.parameters()) #it is genrator it generat the value on the fly.\n",
        "epochs = 1000\n",
        "#define the loop\n",
        "for epoch in range(epochs):\n",
        "    y_pred = Modle(x_train)\n",
        "    loss =loss_function(y_pred,y_train.float())\n",
        "\n",
        "    optimizer.zero_grad() #for the next epoch last gradient will be zero.\n",
        "    #backward propagation\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step() #for paramter update\n",
        "\n",
        "    #print loss in each epochs\n",
        "    print(f\"epoch,{epoch + 1}, loss: {loss.item()}\")\n",
        "    #print accuracy\n",
        "    with torch.no_grad():\n",
        "      y_pred = Modle.forward(x_train)\n",
        "      y_pred = (y_pred > 0.5).float()\n",
        "      accuracy = (y_pred == y_train).float().mean()\n",
        "      print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVcHwDDwNwPE",
        "outputId": "2c67063e-0a5d-4bd2-d315-bf553061697f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch,1, loss: 0.785914421081543\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,2, loss: 0.7847326993942261\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,3, loss: 0.783824622631073\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,4, loss: 0.7829216718673706\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,5, loss: 0.7820240259170532\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,6, loss: 0.7811772227287292\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,7, loss: 0.7804462313652039\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,8, loss: 0.7797192335128784\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,9, loss: 0.7789961695671082\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,10, loss: 0.7783351540565491\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,11, loss: 0.7777438163757324\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,12, loss: 0.7771555781364441\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,13, loss: 0.7765703797340393\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,14, loss: 0.775987982749939\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,15, loss: 0.7754086256027222\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,16, loss: 0.7748321890830994\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,17, loss: 0.7742586135864258\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,18, loss: 0.7736880779266357\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,19, loss: 0.7731202840805054\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,20, loss: 0.7725553512573242\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,21, loss: 0.7719933986663818\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,22, loss: 0.7714342474937439\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,23, loss: 0.7708778977394104\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,24, loss: 0.7703243494033813\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,25, loss: 0.7697737812995911\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,26, loss: 0.7692258358001709\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,27, loss: 0.7686805129051208\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,28, loss: 0.7681382894515991\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,29, loss: 0.767598569393158\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,30, loss: 0.767061710357666\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,31, loss: 0.766527533531189\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,32, loss: 0.7659960985183716\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,33, loss: 0.7654672861099243\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,34, loss: 0.7649646997451782\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,35, loss: 0.7644914388656616\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,36, loss: 0.7640204429626465\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,37, loss: 0.7635518312454224\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,38, loss: 0.7630854249000549\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,39, loss: 0.7626212239265442\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,40, loss: 0.7621594071388245\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,41, loss: 0.7616996765136719\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,42, loss: 0.7612422704696655\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,43, loss: 0.7607870697975159\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,44, loss: 0.7603341341018677\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,45, loss: 0.7598832845687866\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,46, loss: 0.759434700012207\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,47, loss: 0.7589882016181946\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,48, loss: 0.7585439682006836\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,49, loss: 0.7581018209457397\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,50, loss: 0.7576618194580078\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,51, loss: 0.7572240829467773\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,52, loss: 0.7567883729934692\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,53, loss: 0.7563547492027283\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,54, loss: 0.755923330783844\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,55, loss: 0.7554939985275269\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,56, loss: 0.7550666928291321\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,57, loss: 0.7546415328979492\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,58, loss: 0.754218339920044\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,59, loss: 0.7537972927093506\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,60, loss: 0.7533783316612244\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,61, loss: 0.7529613375663757\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,62, loss: 0.752546489238739\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,63, loss: 0.7521335482597351\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,64, loss: 0.7517226934432983\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,65, loss: 0.7513138055801392\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,66, loss: 0.7509069442749023\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,67, loss: 0.7505021095275879\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,68, loss: 0.7500990629196167\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,69, loss: 0.7496982216835022\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,70, loss: 0.7492992281913757\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,71, loss: 0.7489022016525269\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,72, loss: 0.7485071420669556\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,73, loss: 0.7481139898300171\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,74, loss: 0.7477227449417114\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,75, loss: 0.7473334074020386\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,76, loss: 0.7469459772109985\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,77, loss: 0.7465605735778809\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,78, loss: 0.7461770176887512\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,79, loss: 0.7457951307296753\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,80, loss: 0.745415449142456\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,81, loss: 0.745037317276001\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,82, loss: 0.7446612119674683\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,83, loss: 0.7442870736122131\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,84, loss: 0.7439144849777222\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,85, loss: 0.7435438632965088\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,86, loss: 0.7431750893592834\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,87, loss: 0.7428081035614014\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,88, loss: 0.742442786693573\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,89, loss: 0.7420795559883118\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,90, loss: 0.7417179346084595\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,91, loss: 0.7413581013679504\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,92, loss: 0.7409999370574951\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,93, loss: 0.7406437993049622\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,94, loss: 0.7402891516685486\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,95, loss: 0.739936351776123\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,96, loss: 0.7395852208137512\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,97, loss: 0.7392359972000122\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,98, loss: 0.7388883829116821\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,99, loss: 0.738542377948761\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,100, loss: 0.7381982207298279\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,101, loss: 0.7378557324409485\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,102, loss: 0.7375149130821228\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,103, loss: 0.7371757626533508\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,104, loss: 0.7368383407592773\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,105, loss: 0.7365025281906128\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,106, loss: 0.7361683249473572\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,107, loss: 0.7358358502388\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,108, loss: 0.7355049848556519\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,109, loss: 0.7351757287979126\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,110, loss: 0.7348480224609375\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,111, loss: 0.7345220446586609\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,112, loss: 0.734197735786438\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,113, loss: 0.7338749170303345\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,114, loss: 0.7335537672042847\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,115, loss: 0.7332342267036438\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,116, loss: 0.7329161167144775\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,117, loss: 0.732599675655365\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,118, loss: 0.7322847247123718\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,119, loss: 0.7319714426994324\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,120, loss: 0.7316596508026123\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,121, loss: 0.7313493490219116\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,122, loss: 0.7310406565666199\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,123, loss: 0.7307335138320923\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,124, loss: 0.7304278016090393\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,125, loss: 0.7301236391067505\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,126, loss: 0.729820966720581\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,127, loss: 0.729519784450531\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,128, loss: 0.7292200922966003\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,129, loss: 0.7289218902587891\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,130, loss: 0.7286251783370972\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,131, loss: 0.7283300161361694\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,132, loss: 0.7280361652374268\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,133, loss: 0.727743923664093\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,134, loss: 0.7274529933929443\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,135, loss: 0.7271634340286255\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,136, loss: 0.7268754839897156\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,137, loss: 0.7265888452529907\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,138, loss: 0.72630375623703\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,139, loss: 0.7260199785232544\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,140, loss: 0.7257375717163086\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,141, loss: 0.7254565954208374\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,142, loss: 0.725176990032196\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,143, loss: 0.7248989343643188\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,144, loss: 0.7246220111846924\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,145, loss: 0.7243465185165405\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,146, loss: 0.7240725755691528\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,147, loss: 0.7237998247146606\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,148, loss: 0.7235283851623535\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,149, loss: 0.723258376121521\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,150, loss: 0.7229896783828735\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,151, loss: 0.7227222919464111\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,152, loss: 0.7224562764167786\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,153, loss: 0.7221915125846863\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,154, loss: 0.7219281196594238\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,155, loss: 0.7216659784317017\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,156, loss: 0.7214052081108093\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,157, loss: 0.7211456894874573\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,158, loss: 0.7208873629570007\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,159, loss: 0.7206304669380188\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,160, loss: 0.7203748226165771\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,161, loss: 0.7201204299926758\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,162, loss: 0.7198671698570251\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,163, loss: 0.7196153402328491\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,164, loss: 0.7193647027015686\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,165, loss: 0.7191151976585388\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,166, loss: 0.7188670635223389\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,167, loss: 0.7186200618743896\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,168, loss: 0.7183743715286255\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,169, loss: 0.7181297540664673\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,170, loss: 0.7178865075111389\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,171, loss: 0.7176443934440613\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,172, loss: 0.7174035906791687\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,173, loss: 0.7171638607978821\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,174, loss: 0.7169253826141357\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,175, loss: 0.7166879773139954\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,176, loss: 0.7164517641067505\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,177, loss: 0.7162167429924011\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,178, loss: 0.7159830331802368\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,179, loss: 0.7157503366470337\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,180, loss: 0.7155188322067261\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,181, loss: 0.7152884006500244\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,182, loss: 0.715059220790863\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,183, loss: 0.7148311734199524\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,184, loss: 0.7146040797233582\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,185, loss: 0.7143782377243042\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,186, loss: 0.7141534686088562\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,187, loss: 0.7139298915863037\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,188, loss: 0.7137073874473572\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,189, loss: 0.7134860754013062\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,190, loss: 0.7132657170295715\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,191, loss: 0.7130464315414429\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,192, loss: 0.7128282785415649\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,193, loss: 0.7126112580299377\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,194, loss: 0.712395191192627\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,195, loss: 0.7121803164482117\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,196, loss: 0.7119664549827576\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,197, loss: 0.7117536067962646\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,198, loss: 0.7115419507026672\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,199, loss: 0.7113311886787415\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,200, loss: 0.7111214995384216\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,201, loss: 0.7109128832817078\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,202, loss: 0.7107052803039551\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,203, loss: 0.7104986906051636\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,204, loss: 0.7102932333946228\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,205, loss: 0.7100886702537537\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,206, loss: 0.7098852396011353\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,207, loss: 0.7096826434135437\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,208, loss: 0.7094811201095581\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,209, loss: 0.7092806100845337\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,210, loss: 0.7090810537338257\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,211, loss: 0.7088824510574341\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,212, loss: 0.7086849212646484\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,213, loss: 0.7084883451461792\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,214, loss: 0.7082927227020264\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,215, loss: 0.7080980539321899\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,216, loss: 0.7079043984413147\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,217, loss: 0.7077116370201111\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,218, loss: 0.7075198888778687\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,219, loss: 0.7073289752006531\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,220, loss: 0.7071391344070435\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,221, loss: 0.7069501876831055\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,222, loss: 0.7067620754241943\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,223, loss: 0.7065749764442444\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,224, loss: 0.7063888311386108\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,225, loss: 0.7062035799026489\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,226, loss: 0.7060192227363586\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,227, loss: 0.7058358192443848\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,228, loss: 0.705653190612793\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,229, loss: 0.7054715156555176\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,230, loss: 0.7052907347679138\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,231, loss: 0.705111026763916\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,232, loss: 0.7049319744110107\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,233, loss: 0.7047539949417114\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,234, loss: 0.7045766115188599\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,235, loss: 0.7044003009796143\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,236, loss: 0.7042249441146851\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,237, loss: 0.7040501832962036\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,238, loss: 0.7038764357566833\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,239, loss: 0.7037035822868347\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,240, loss: 0.7035315036773682\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,241, loss: 0.703360378742218\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,242, loss: 0.7031899094581604\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,243, loss: 0.703020453453064\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,244, loss: 0.7028517723083496\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,245, loss: 0.7026838660240173\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,246, loss: 0.7025168538093567\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,247, loss: 0.7023506164550781\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,248, loss: 0.7021851539611816\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,249, loss: 0.702020525932312\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,250, loss: 0.7018568515777588\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,251, loss: 0.7016937732696533\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,252, loss: 0.7015315890312195\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,253, loss: 0.7013701796531677\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,254, loss: 0.7012096047401428\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,255, loss: 0.7010498046875\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,256, loss: 0.7008907198905945\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,257, loss: 0.7007325291633606\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,258, loss: 0.700575053691864\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,259, loss: 0.7004183530807495\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,260, loss: 0.7002624273300171\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,261, loss: 0.700107216835022\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,262, loss: 0.6999528408050537\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,263, loss: 0.699799120426178\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,264, loss: 0.6996461153030396\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,265, loss: 0.6994940638542175\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,266, loss: 0.6993426084518433\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,267, loss: 0.6991919875144958\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,268, loss: 0.6990419626235962\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,269, loss: 0.6988927721977234\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,270, loss: 0.6987442374229431\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,271, loss: 0.6985964775085449\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,272, loss: 0.6984494924545288\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,273, loss: 0.6983031034469604\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,274, loss: 0.698157548904419\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,275, loss: 0.6980125904083252\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,276, loss: 0.6978684663772583\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,277, loss: 0.6977249979972839\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,278, loss: 0.6975821852684021\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,279, loss: 0.6974400281906128\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,280, loss: 0.6972987055778503\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,281, loss: 0.6971579194068909\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,282, loss: 0.6970179677009583\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,283, loss: 0.6968785524368286\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,284, loss: 0.696739912033081\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,285, loss: 0.6966018676757812\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,286, loss: 0.6964646577835083\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,287, loss: 0.6963278651237488\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,288, loss: 0.6961919069290161\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,289, loss: 0.696056604385376\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,290, loss: 0.695921778678894\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,291, loss: 0.695787787437439\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,292, loss: 0.6956545114517212\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,293, loss: 0.6955217123031616\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,294, loss: 0.6953896880149841\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,295, loss: 0.6952582001686096\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,296, loss: 0.6951273679733276\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,297, loss: 0.6949971914291382\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,298, loss: 0.6948676109313965\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,299, loss: 0.6947387456893921\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,300, loss: 0.6946104764938354\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,301, loss: 0.6944828033447266\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,302, loss: 0.6943556666374207\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,303, loss: 0.694229245185852\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,304, loss: 0.6941033601760864\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,305, loss: 0.6939781904220581\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,306, loss: 0.693853497505188\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,307, loss: 0.6937295198440552\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,308, loss: 0.6936061382293701\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,309, loss: 0.6934833526611328\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,310, loss: 0.6933610439300537\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,311, loss: 0.6932393312454224\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,312, loss: 0.6931184530258179\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,313, loss: 0.6929978132247925\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,314, loss: 0.6928779482841492\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,315, loss: 0.6927586793899536\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,316, loss: 0.6926398873329163\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,317, loss: 0.6925216913223267\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,318, loss: 0.6924040913581848\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,319, loss: 0.6922870874404907\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,320, loss: 0.6921705007553101\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,321, loss: 0.6920546293258667\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,322, loss: 0.6919392347335815\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,323, loss: 0.6918244361877441\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,324, loss: 0.6917101740837097\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,325, loss: 0.691596508026123\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,326, loss: 0.6914832592010498\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,327, loss: 0.6913706064224243\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,328, loss: 0.6912585496902466\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,329, loss: 0.6911470293998718\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,330, loss: 0.6910360455513\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,331, loss: 0.6909254789352417\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,332, loss: 0.6908155679702759\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,333, loss: 0.6907060742378235\n",
            "accuracy: 0.4000000059604645\n",
            "epoch,334, loss: 0.6905971765518188\n",
            "accuracy: 0.699999988079071\n",
            "epoch,335, loss: 0.6904887557029724\n",
            "accuracy: 0.699999988079071\n",
            "epoch,336, loss: 0.6903809309005737\n",
            "accuracy: 0.699999988079071\n",
            "epoch,337, loss: 0.6902735829353333\n",
            "accuracy: 0.699999988079071\n",
            "epoch,338, loss: 0.690166711807251\n",
            "accuracy: 0.699999988079071\n",
            "epoch,339, loss: 0.6900603175163269\n",
            "accuracy: 0.699999988079071\n",
            "epoch,340, loss: 0.6899559497833252\n",
            "accuracy: 0.699999988079071\n",
            "epoch,341, loss: 0.6898531913757324\n",
            "accuracy: 0.699999988079071\n",
            "epoch,342, loss: 0.6897484064102173\n",
            "accuracy: 0.699999988079071\n",
            "epoch,343, loss: 0.6896439790725708\n",
            "accuracy: 0.699999988079071\n",
            "epoch,344, loss: 0.6895400881767273\n",
            "accuracy: 0.699999988079071\n",
            "epoch,345, loss: 0.6894367337226868\n",
            "accuracy: 0.699999988079071\n",
            "epoch,346, loss: 0.6893340349197388\n",
            "accuracy: 0.699999988079071\n",
            "epoch,347, loss: 0.6892353296279907\n",
            "accuracy: 0.699999988079071\n",
            "epoch,348, loss: 0.6891332864761353\n",
            "accuracy: 0.699999988079071\n",
            "epoch,349, loss: 0.6890317797660828\n",
            "accuracy: 0.699999988079071\n",
            "epoch,350, loss: 0.6889308094978333\n",
            "accuracy: 0.699999988079071\n",
            "epoch,351, loss: 0.6888303160667419\n",
            "accuracy: 0.699999988079071\n",
            "epoch,352, loss: 0.6887302398681641\n",
            "accuracy: 0.699999988079071\n",
            "epoch,353, loss: 0.6886329054832458\n",
            "accuracy: 0.699999988079071\n",
            "epoch,354, loss: 0.6885351538658142\n",
            "accuracy: 0.699999988079071\n",
            "epoch,355, loss: 0.6884365677833557\n",
            "accuracy: 0.699999988079071\n",
            "epoch,356, loss: 0.6883383989334106\n",
            "accuracy: 0.699999988079071\n",
            "epoch,357, loss: 0.688240647315979\n",
            "accuracy: 0.699999988079071\n",
            "epoch,358, loss: 0.6881433725357056\n",
            "accuracy: 0.699999988079071\n",
            "epoch,359, loss: 0.6880465745925903\n",
            "accuracy: 0.699999988079071\n",
            "epoch,360, loss: 0.6879533529281616\n",
            "accuracy: 0.699999988079071\n",
            "epoch,361, loss: 0.6878577470779419\n",
            "accuracy: 0.699999988079071\n",
            "epoch,362, loss: 0.6877622604370117\n",
            "accuracy: 0.699999988079071\n",
            "epoch,363, loss: 0.687667191028595\n",
            "accuracy: 0.699999988079071\n",
            "epoch,364, loss: 0.6875725984573364\n",
            "accuracy: 0.699999988079071\n",
            "epoch,365, loss: 0.6874783635139465\n",
            "accuracy: 0.699999988079071\n",
            "epoch,366, loss: 0.6873846650123596\n",
            "accuracy: 0.699999988079071\n",
            "epoch,367, loss: 0.6872947812080383\n",
            "accuracy: 0.699999988079071\n",
            "epoch,368, loss: 0.687201976776123\n",
            "accuracy: 0.699999988079071\n",
            "epoch,369, loss: 0.6871094703674316\n",
            "accuracy: 0.699999988079071\n",
            "epoch,370, loss: 0.6870174407958984\n",
            "accuracy: 0.699999988079071\n",
            "epoch,371, loss: 0.6869258880615234\n",
            "accuracy: 0.699999988079071\n",
            "epoch,372, loss: 0.6868346929550171\n",
            "accuracy: 0.699999988079071\n",
            "epoch,373, loss: 0.6867440342903137\n",
            "accuracy: 0.699999988079071\n",
            "epoch,374, loss: 0.6866560578346252\n",
            "accuracy: 0.699999988079071\n",
            "epoch,375, loss: 0.6865670084953308\n",
            "accuracy: 0.699999988079071\n",
            "epoch,376, loss: 0.686477541923523\n",
            "accuracy: 0.699999988079071\n",
            "epoch,377, loss: 0.6863884329795837\n",
            "accuracy: 0.699999988079071\n",
            "epoch,378, loss: 0.6862998008728027\n",
            "accuracy: 0.699999988079071\n",
            "epoch,379, loss: 0.6862115263938904\n",
            "accuracy: 0.699999988079071\n",
            "epoch,380, loss: 0.6861236691474915\n",
            "accuracy: 0.699999988079071\n",
            "epoch,381, loss: 0.6860369443893433\n",
            "accuracy: 0.699999988079071\n",
            "epoch,382, loss: 0.685952365398407\n",
            "accuracy: 0.699999988079071\n",
            "epoch,383, loss: 0.6858657002449036\n",
            "accuracy: 0.699999988079071\n",
            "epoch,384, loss: 0.6857794523239136\n",
            "accuracy: 0.699999988079071\n",
            "epoch,385, loss: 0.6856935620307922\n",
            "accuracy: 0.699999988079071\n",
            "epoch,386, loss: 0.6856080889701843\n",
            "accuracy: 0.699999988079071\n",
            "epoch,387, loss: 0.6855230927467346\n",
            "accuracy: 0.699999988079071\n",
            "epoch,388, loss: 0.6854383945465088\n",
            "accuracy: 0.699999988079071\n",
            "epoch,389, loss: 0.6853549480438232\n",
            "accuracy: 0.699999988079071\n",
            "epoch,390, loss: 0.685273289680481\n",
            "accuracy: 0.699999988079071\n",
            "epoch,391, loss: 0.6851896047592163\n",
            "accuracy: 0.699999988079071\n",
            "epoch,392, loss: 0.6851065158843994\n",
            "accuracy: 0.699999988079071\n",
            "epoch,393, loss: 0.6850236654281616\n",
            "accuracy: 0.699999988079071\n",
            "epoch,394, loss: 0.6849413514137268\n",
            "accuracy: 0.699999988079071\n",
            "epoch,395, loss: 0.6848593950271606\n",
            "accuracy: 0.699999988079071\n",
            "epoch,396, loss: 0.6847777366638184\n",
            "accuracy: 0.699999988079071\n",
            "epoch,397, loss: 0.6846965551376343\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,398, loss: 0.6846184730529785\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,399, loss: 0.6845378875732422\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,400, loss: 0.6844577789306641\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,401, loss: 0.684377908706665\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,402, loss: 0.684298574924469\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,403, loss: 0.684219479560852\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,404, loss: 0.6841408610343933\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,405, loss: 0.6840624809265137\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,406, loss: 0.6839853525161743\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,407, loss: 0.68390953540802\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,408, loss: 0.6838322877883911\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,409, loss: 0.6837553381919861\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,410, loss: 0.6836787462234497\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,411, loss: 0.6836024522781372\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,412, loss: 0.6835265159606934\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,413, loss: 0.6834510564804077\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,414, loss: 0.6833758354187012\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,415, loss: 0.6833011507987976\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,416, loss: 0.6832289695739746\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,417, loss: 0.6831547617912292\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,418, loss: 0.6830809116363525\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,419, loss: 0.6830073595046997\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,420, loss: 0.6829341650009155\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,421, loss: 0.682861328125\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,422, loss: 0.6827887296676636\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,423, loss: 0.6827165484428406\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,424, loss: 0.6826446652412415\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,425, loss: 0.6825736165046692\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,426, loss: 0.6825041770935059\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,427, loss: 0.6824332475662231\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,428, loss: 0.6823626160621643\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,429, loss: 0.6822923421859741\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,430, loss: 0.6822224855422974\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,431, loss: 0.6821526885032654\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,432, loss: 0.6820833683013916\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,433, loss: 0.6820142865180969\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,434, loss: 0.6819456219673157\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,435, loss: 0.6818772554397583\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,436, loss: 0.6818103790283203\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,437, loss: 0.6817433834075928\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,438, loss: 0.6816757917404175\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,439, loss: 0.6816086769104004\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,440, loss: 0.6815417408943176\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,441, loss: 0.6814752221107483\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,442, loss: 0.6814087629318237\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,443, loss: 0.6813427805900574\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,444, loss: 0.6812769770622253\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,445, loss: 0.6812115907669067\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,446, loss: 0.6811464428901672\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,447, loss: 0.6810816526412964\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,448, loss: 0.6810189485549927\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,449, loss: 0.6809545755386353\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,450, loss: 0.6808906197547913\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,451, loss: 0.6808268427848816\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,452, loss: 0.6807634234428406\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,453, loss: 0.6807003021240234\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,454, loss: 0.6806373000144958\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,455, loss: 0.6805747151374817\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,456, loss: 0.6805123090744019\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,457, loss: 0.6804503202438354\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,458, loss: 0.6803885698318481\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,459, loss: 0.6803270578384399\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,460, loss: 0.6802663803100586\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,461, loss: 0.6802065372467041\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,462, loss: 0.680145800113678\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,463, loss: 0.680085301399231\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,464, loss: 0.680025041103363\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,465, loss: 0.6799651384353638\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,466, loss: 0.6799055337905884\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,467, loss: 0.6798459887504578\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,468, loss: 0.6797868609428406\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,469, loss: 0.679728090763092\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,470, loss: 0.6796694993972778\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,471, loss: 0.679611086845398\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,472, loss: 0.6795529127120972\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,473, loss: 0.6794949769973755\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,474, loss: 0.6794376373291016\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,475, loss: 0.6793815493583679\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,476, loss: 0.6793244481086731\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,477, loss: 0.6792675256729126\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,478, loss: 0.679210901260376\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,479, loss: 0.6791545152664185\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,480, loss: 0.6790983080863953\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,481, loss: 0.6790424585342407\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,482, loss: 0.6789867877960205\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,483, loss: 0.6789313554763794\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,484, loss: 0.6788761019706726\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,485, loss: 0.6788211464881897\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,486, loss: 0.6787664890289307\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,487, loss: 0.678712010383606\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,488, loss: 0.6786577105522156\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,489, loss: 0.6786037683486938\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,490, loss: 0.6785499453544617\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,491, loss: 0.6784970164299011\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,492, loss: 0.6784443259239197\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,493, loss: 0.67839115858078\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,494, loss: 0.678338348865509\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,495, loss: 0.6782855987548828\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,496, loss: 0.67823326587677\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,497, loss: 0.6781810522079468\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,498, loss: 0.6781290769577026\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,499, loss: 0.678077220916748\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,500, loss: 0.6780256032943726\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,501, loss: 0.6779743432998657\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,502, loss: 0.6779232621192932\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,503, loss: 0.6778723001480103\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,504, loss: 0.677821695804596\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,505, loss: 0.6777711510658264\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,506, loss: 0.6777209043502808\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,507, loss: 0.6776708364486694\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,508, loss: 0.677621066570282\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,509, loss: 0.6775714159011841\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,510, loss: 0.6775220632553101\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,511, loss: 0.6774729490280151\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,512, loss: 0.6774248480796814\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,513, loss: 0.6773760318756104\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,514, loss: 0.6773273348808289\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,515, loss: 0.677278995513916\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,516, loss: 0.677230715751648\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,517, loss: 0.6771827936172485\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,518, loss: 0.6771349906921387\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,519, loss: 0.6770874261856079\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,520, loss: 0.6770399808883667\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,521, loss: 0.6769927740097046\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,522, loss: 0.6769458055496216\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,523, loss: 0.6768989562988281\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,524, loss: 0.676852285861969\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,525, loss: 0.676805853843689\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,526, loss: 0.6767596006393433\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,527, loss: 0.6767135858535767\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,528, loss: 0.6766676902770996\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,529, loss: 0.6766220927238464\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,530, loss: 0.676576554775238\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,531, loss: 0.6765312552452087\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,532, loss: 0.6764861941337585\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,533, loss: 0.6764413118362427\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,534, loss: 0.6763965487480164\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,535, loss: 0.6763520240783691\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,536, loss: 0.6763075590133667\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,537, loss: 0.6762634515762329\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,538, loss: 0.6762194633483887\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,539, loss: 0.6761756539344788\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,540, loss: 0.6761319637298584\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,541, loss: 0.6760891675949097\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,542, loss: 0.6760457158088684\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,543, loss: 0.6760025024414062\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,544, loss: 0.6759597063064575\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,545, loss: 0.675916850566864\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,546, loss: 0.6758741736412048\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,547, loss: 0.6758317351341248\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,548, loss: 0.675789475440979\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,549, loss: 0.6757473945617676\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,550, loss: 0.6757053136825562\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,551, loss: 0.6756635904312134\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,552, loss: 0.6756219863891602\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,553, loss: 0.675580620765686\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,554, loss: 0.6755393743515015\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,555, loss: 0.6754981279373169\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,556, loss: 0.675457239151001\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,557, loss: 0.6754163503646851\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,558, loss: 0.6753758192062378\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,559, loss: 0.6753354072570801\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,560, loss: 0.6752950549125671\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,561, loss: 0.6752549409866333\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,562, loss: 0.6752148866653442\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,563, loss: 0.675175130367279\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,564, loss: 0.6751354932785034\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,565, loss: 0.6750959753990173\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,566, loss: 0.6750565767288208\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,567, loss: 0.6750174164772034\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,568, loss: 0.6749784350395203\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,569, loss: 0.6749395132064819\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,570, loss: 0.6749006509780884\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,571, loss: 0.6748622059822083\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,572, loss: 0.6748236417770386\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,573, loss: 0.6747854351997375\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,574, loss: 0.6747473478317261\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,575, loss: 0.6747093200683594\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,576, loss: 0.6746715307235718\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,577, loss: 0.674633800983429\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,578, loss: 0.6745961904525757\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,579, loss: 0.6745587587356567\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,580, loss: 0.6745215654373169\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,581, loss: 0.6744844317436218\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,582, loss: 0.6744474172592163\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,583, loss: 0.6744105815887451\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,584, loss: 0.6743739247322083\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,585, loss: 0.6743373870849609\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,586, loss: 0.6743009686470032\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,587, loss: 0.674264669418335\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,588, loss: 0.6742285490036011\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,589, loss: 0.6741925477981567\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,590, loss: 0.674156665802002\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,591, loss: 0.6741209626197815\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,592, loss: 0.6740853190422058\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,593, loss: 0.6740498542785645\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,594, loss: 0.6740146279335022\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,595, loss: 0.6739794015884399\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,596, loss: 0.6739442944526672\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,597, loss: 0.6739094257354736\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,598, loss: 0.67387455701828\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,599, loss: 0.6738399267196655\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,600, loss: 0.6738054752349854\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,601, loss: 0.6737710237503052\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,602, loss: 0.6737367510795593\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,603, loss: 0.6737025380134583\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,604, loss: 0.6736685633659363\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,605, loss: 0.6736346483230591\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,606, loss: 0.6736009120941162\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,607, loss: 0.6735672354698181\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,608, loss: 0.6735337376594543\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,609, loss: 0.6735004186630249\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,610, loss: 0.6734670400619507\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,611, loss: 0.6734338998794556\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,612, loss: 0.67340087890625\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,613, loss: 0.6733679175376892\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,614, loss: 0.673335075378418\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,615, loss: 0.6733024716377258\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,616, loss: 0.6732699275016785\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,617, loss: 0.6732374429702759\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,618, loss: 0.6732051968574524\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,619, loss: 0.6731730103492737\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,620, loss: 0.6731408834457397\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,621, loss: 0.6731089353561401\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,622, loss: 0.6730770468711853\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,623, loss: 0.6730453372001648\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,624, loss: 0.6730137467384338\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,625, loss: 0.6729822754859924\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,626, loss: 0.672950804233551\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,627, loss: 0.672919511795044\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,628, loss: 0.6728883981704712\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,629, loss: 0.6728572845458984\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,630, loss: 0.67282634973526\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,631, loss: 0.6727954745292664\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,632, loss: 0.6727647185325623\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,633, loss: 0.6727341413497925\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,634, loss: 0.6727035641670227\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,635, loss: 0.6726731657981873\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,636, loss: 0.6726428270339966\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,637, loss: 0.6726126670837402\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,638, loss: 0.6725826263427734\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,639, loss: 0.6725526452064514\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,640, loss: 0.672522783279419\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,641, loss: 0.6724929213523865\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,642, loss: 0.6724632382392883\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,643, loss: 0.6724337339401245\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,644, loss: 0.6724042296409607\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,645, loss: 0.6723748445510864\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,646, loss: 0.6723456382751465\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,647, loss: 0.6723163723945618\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,648, loss: 0.6722873449325562\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,649, loss: 0.6722584366798401\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,650, loss: 0.6722295880317688\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,651, loss: 0.6722007393836975\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,652, loss: 0.6721720695495605\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,653, loss: 0.6721434593200684\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,654, loss: 0.6721149682998657\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,655, loss: 0.6720866560935974\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,656, loss: 0.6720582842826843\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,657, loss: 0.6720300912857056\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,658, loss: 0.6720020771026611\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,659, loss: 0.6719740629196167\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,660, loss: 0.6719461679458618\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,661, loss: 0.6719182729721069\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,662, loss: 0.6718905568122864\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,663, loss: 0.6718629598617554\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,664, loss: 0.6718354225158691\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,665, loss: 0.6718079447746277\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,666, loss: 0.6717806458473206\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,667, loss: 0.6717534065246582\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,668, loss: 0.6717262268066406\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,669, loss: 0.671699047088623\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,670, loss: 0.6716720461845398\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,671, loss: 0.6716451644897461\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,672, loss: 0.6716183423995972\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,673, loss: 0.6715916395187378\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,674, loss: 0.6715649366378784\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,675, loss: 0.6715384721755981\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,676, loss: 0.6715120077133179\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,677, loss: 0.6714855432510376\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,678, loss: 0.6714591979980469\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,679, loss: 0.6714330315589905\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,680, loss: 0.6714068651199341\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,681, loss: 0.6713808178901672\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,682, loss: 0.6713548898696899\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,683, loss: 0.6713289618492126\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,684, loss: 0.6713032126426697\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,685, loss: 0.6712774038314819\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,686, loss: 0.6712518334388733\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,687, loss: 0.6712261438369751\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,688, loss: 0.6712007522583008\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,689, loss: 0.6711753606796265\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,690, loss: 0.6711500883102417\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,691, loss: 0.6711247563362122\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,692, loss: 0.6710996031761169\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,693, loss: 0.6710745096206665\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,694, loss: 0.6710495352745056\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,695, loss: 0.6710245609283447\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,696, loss: 0.6709997653961182\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,697, loss: 0.6709749102592468\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,698, loss: 0.6709502935409546\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,699, loss: 0.6709256172180176\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,700, loss: 0.6709011793136597\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,701, loss: 0.6708766222000122\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,702, loss: 0.6708521842956543\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,703, loss: 0.6708278656005859\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,704, loss: 0.6708036661148071\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,705, loss: 0.6707794070243835\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,706, loss: 0.6707553267478943\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,707, loss: 0.6707313656806946\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,708, loss: 0.6707073450088501\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,709, loss: 0.6706835031509399\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,710, loss: 0.6706597208976746\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,711, loss: 0.6706358194351196\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,712, loss: 0.6706122159957886\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,713, loss: 0.6705886125564575\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,714, loss: 0.6705650687217712\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,715, loss: 0.6705416440963745\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,716, loss: 0.6705182194709778\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,717, loss: 0.6704949140548706\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,718, loss: 0.6704716682434082\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,719, loss: 0.6704484224319458\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,720, loss: 0.670425295829773\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,721, loss: 0.6704022288322449\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,722, loss: 0.6703792810440063\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,723, loss: 0.6703563928604126\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,724, loss: 0.6703335046768188\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,725, loss: 0.6703106760978699\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,726, loss: 0.6702879667282104\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,727, loss: 0.6702653169631958\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,728, loss: 0.6702426075935364\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,729, loss: 0.6702201962471008\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,730, loss: 0.6701976656913757\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,731, loss: 0.6701752543449402\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,732, loss: 0.6701529026031494\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,733, loss: 0.6701305508613586\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,734, loss: 0.6701083779335022\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,735, loss: 0.6700862050056458\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,736, loss: 0.6700640916824341\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,737, loss: 0.670042097568512\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,738, loss: 0.6700201034545898\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,739, loss: 0.6699981689453125\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,740, loss: 0.6699764132499695\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,741, loss: 0.6699546575546265\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,742, loss: 0.6699329018592834\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,743, loss: 0.6699111461639404\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,744, loss: 0.6698895692825317\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,745, loss: 0.6698679327964783\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,746, loss: 0.6698465347290039\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,747, loss: 0.6698250770568848\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,748, loss: 0.6698036789894104\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,749, loss: 0.6697823405265808\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,750, loss: 0.6697611212730408\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,751, loss: 0.669739842414856\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,752, loss: 0.6697187423706055\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,753, loss: 0.669697642326355\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,754, loss: 0.6696765422821045\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,755, loss: 0.6696556210517883\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,756, loss: 0.6696346998214722\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,757, loss: 0.669613778591156\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,758, loss: 0.6695929765701294\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,759, loss: 0.6695722341537476\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,760, loss: 0.6695514917373657\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,761, loss: 0.6695308685302734\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,762, loss: 0.6695101857185364\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,763, loss: 0.6694896817207336\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,764, loss: 0.6694691181182861\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,765, loss: 0.669448733329773\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,766, loss: 0.6694282293319702\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,767, loss: 0.6694080233573914\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,768, loss: 0.669387698173523\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,769, loss: 0.6693674325942993\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,770, loss: 0.6693472266197205\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,771, loss: 0.6693270802497864\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,772, loss: 0.6693069934844971\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,773, loss: 0.6692869663238525\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,774, loss: 0.669266939163208\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,775, loss: 0.669247031211853\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,776, loss: 0.6692271828651428\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,777, loss: 0.6692072153091431\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,778, loss: 0.6691875457763672\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,779, loss: 0.669167697429657\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,780, loss: 0.6691480278968811\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,781, loss: 0.6691283583641052\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,782, loss: 0.6691087484359741\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,783, loss: 0.6690892577171326\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,784, loss: 0.6690697073936462\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,785, loss: 0.6690502762794495\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,786, loss: 0.6690307855606079\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,787, loss: 0.6690114736557007\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,788, loss: 0.6689922213554382\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,789, loss: 0.6689728498458862\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,790, loss: 0.6689537167549133\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,791, loss: 0.6689344644546509\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,792, loss: 0.6689153909683228\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,793, loss: 0.6688962578773499\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,794, loss: 0.6688772439956665\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,795, loss: 0.6688581705093384\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,796, loss: 0.6688392162322998\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,797, loss: 0.6688202619552612\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,798, loss: 0.668801486492157\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,799, loss: 0.6687825918197632\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,800, loss: 0.6687637567520142\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,801, loss: 0.6687451004981995\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,802, loss: 0.66872638463974\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,803, loss: 0.6687076091766357\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,804, loss: 0.6686890721321106\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,805, loss: 0.6686704754829407\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,806, loss: 0.6686519384384155\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,807, loss: 0.6686334609985352\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,808, loss: 0.6686149835586548\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,809, loss: 0.6685965657234192\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,810, loss: 0.6685782074928284\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,811, loss: 0.6685598492622375\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,812, loss: 0.6685416102409363\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,813, loss: 0.6685233116149902\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,814, loss: 0.668505072593689\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,815, loss: 0.6684869527816772\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,816, loss: 0.6684688329696655\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,817, loss: 0.6684507131576538\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,818, loss: 0.6684325933456421\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,819, loss: 0.6684147119522095\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,820, loss: 0.6683966517448425\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,821, loss: 0.6683787107467651\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,822, loss: 0.668360710144043\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,823, loss: 0.6683428883552551\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,824, loss: 0.6683250665664673\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,825, loss: 0.6683073043823242\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,826, loss: 0.6682895421981812\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,827, loss: 0.6682717800140381\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,828, loss: 0.6682541370391846\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,829, loss: 0.668236494064331\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,830, loss: 0.6682189106941223\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,831, loss: 0.6682012677192688\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,832, loss: 0.6681837439537048\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,833, loss: 0.6681662797927856\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,834, loss: 0.6681486964225769\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,835, loss: 0.6681313514709473\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,836, loss: 0.6681139469146729\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,837, loss: 0.6680966019630432\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,838, loss: 0.6680792570114136\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,839, loss: 0.6680619716644287\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,840, loss: 0.6680447459220886\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,841, loss: 0.6680275201797485\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,842, loss: 0.6680103540420532\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,843, loss: 0.6679930686950684\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,844, loss: 0.6679759621620178\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,845, loss: 0.6679588556289673\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,846, loss: 0.6679418683052063\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,847, loss: 0.6679247617721558\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,848, loss: 0.6679078340530396\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,849, loss: 0.6678908467292786\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,850, loss: 0.6678739190101624\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,851, loss: 0.6678569912910461\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,852, loss: 0.6678401231765747\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,853, loss: 0.6678232550621033\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,854, loss: 0.6678065061569214\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,855, loss: 0.6677897572517395\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,856, loss: 0.6677729487419128\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,857, loss: 0.6677562594413757\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,858, loss: 0.6677396893501282\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,859, loss: 0.6677229404449463\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,860, loss: 0.667706310749054\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,861, loss: 0.6676896810531616\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,862, loss: 0.6676731705665588\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,863, loss: 0.6676566004753113\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,864, loss: 0.6676400899887085\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,865, loss: 0.6676236391067505\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,866, loss: 0.6676071882247925\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,867, loss: 0.6675907373428345\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,868, loss: 0.6675743460655212\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,869, loss: 0.667557954788208\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,870, loss: 0.6675416231155396\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,871, loss: 0.6675254106521606\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,872, loss: 0.6675090193748474\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,873, loss: 0.6674928665161133\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,874, loss: 0.6674765944480896\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,875, loss: 0.6674604415893555\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,876, loss: 0.6674443483352661\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,877, loss: 0.6674281358718872\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,878, loss: 0.6674120426177979\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,879, loss: 0.6673958897590637\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,880, loss: 0.6673799157142639\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,881, loss: 0.6673637628555298\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,882, loss: 0.66734778881073\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,883, loss: 0.6673318147659302\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,884, loss: 0.6673158407211304\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,885, loss: 0.6672999262809753\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,886, loss: 0.6672840118408203\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,887, loss: 0.6672681570053101\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,888, loss: 0.6672557592391968\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,889, loss: 0.6672415137290955\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,890, loss: 0.66722571849823\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,891, loss: 0.6672118306159973\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,892, loss: 0.6671992540359497\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,893, loss: 0.6671835780143738\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,894, loss: 0.6671680808067322\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,895, loss: 0.6671572327613831\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,896, loss: 0.6671416163444519\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,897, loss: 0.6671260595321655\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,898, loss: 0.6671143174171448\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,899, loss: 0.6670999526977539\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,900, loss: 0.6670844554901123\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,901, loss: 0.6670713424682617\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,902, loss: 0.6670585870742798\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,903, loss: 0.667043149471283\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,904, loss: 0.6670287847518921\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,905, loss: 0.6670173406600952\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,906, loss: 0.6670020222663879\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,907, loss: 0.6669866442680359\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,908, loss: 0.6669762134552002\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,909, loss: 0.666961133480072\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,910, loss: 0.6669458150863647\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,911, loss: 0.6669341921806335\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,912, loss: 0.6669204831123352\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,913, loss: 0.6669052839279175\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,914, loss: 0.6668925881385803\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,915, loss: 0.6668801307678223\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,916, loss: 0.6668649911880493\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,917, loss: 0.6668511629104614\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,918, loss: 0.6668399572372437\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,919, loss: 0.6668249368667603\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,920, loss: 0.6668099761009216\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,921, loss: 0.6668000221252441\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,922, loss: 0.6667850613594055\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,923, loss: 0.6667700409889221\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,924, loss: 0.6667593717575073\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,925, loss: 0.6667453646659851\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,926, loss: 0.6667304039001465\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,927, loss: 0.6667188405990601\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,928, loss: 0.6667059659957886\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,929, loss: 0.66669100522995\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,930, loss: 0.6666787266731262\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,931, loss: 0.6666666865348816\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,932, loss: 0.6666519045829773\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,933, loss: 0.6666385531425476\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,934, loss: 0.6666277050971985\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,935, loss: 0.6666129231452942\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,936, loss: 0.666598916053772\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,937, loss: 0.6665887832641602\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,938, loss: 0.6665741205215454\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,939, loss: 0.6665594577789307\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,940, loss: 0.6665499806404114\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,941, loss: 0.6665356755256653\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,942, loss: 0.6665210127830505\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,943, loss: 0.6665107607841492\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,944, loss: 0.6664972305297852\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,945, loss: 0.6664825677871704\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,946, loss: 0.6664718389511108\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,947, loss: 0.6664589643478394\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,948, loss: 0.6664444804191589\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,949, loss: 0.6664330959320068\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,950, loss: 0.6664209961891174\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,951, loss: 0.666406512260437\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,952, loss: 0.6663945317268372\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,953, loss: 0.6663831472396851\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,954, loss: 0.666368842124939\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,955, loss: 0.6663562059402466\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,956, loss: 0.666345477104187\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,957, loss: 0.6663311719894409\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,958, loss: 0.6663181781768799\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,959, loss: 0.6663079857826233\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,960, loss: 0.6662936806678772\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,961, loss: 0.6662802696228027\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,962, loss: 0.6662706732749939\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,963, loss: 0.6662565469741821\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,964, loss: 0.6662425994873047\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,965, loss: 0.666233479976654\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,966, loss: 0.6662193536758423\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,967, loss: 0.6662051677703857\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,968, loss: 0.6661965250968933\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,969, loss: 0.6661823987960815\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,970, loss: 0.6661683320999146\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,971, loss: 0.6661593317985535\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,972, loss: 0.6661455631256104\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,973, loss: 0.6661315560340881\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,974, loss: 0.666122317314148\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,975, loss: 0.6661089658737183\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,976, loss: 0.6660948991775513\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,977, loss: 0.6660856008529663\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,978, loss: 0.6660724878311157\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,979, loss: 0.6660585403442383\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,980, loss: 0.666049063205719\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,981, loss: 0.6660361886024475\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,982, loss: 0.6660221815109253\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,983, loss: 0.6660125851631165\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,984, loss: 0.6660000085830688\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,985, loss: 0.6659861207008362\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,986, loss: 0.6659762859344482\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,987, loss: 0.6659639477729797\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,988, loss: 0.6659500598907471\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,989, loss: 0.6659403443336487\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,990, loss: 0.6659280061721802\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,991, loss: 0.6659141778945923\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,992, loss: 0.6659043431282043\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,993, loss: 0.6658922433853149\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,994, loss: 0.665878415107727\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,995, loss: 0.6658686995506287\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,996, loss: 0.6658565998077393\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,997, loss: 0.6658428907394409\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,998, loss: 0.6658332943916321\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,999, loss: 0.6658210754394531\n",
            "accuracy: 0.6000000238418579\n",
            "epoch,1000, loss: 0.6658073663711548\n",
            "accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0-u4Fz3PJK-"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARPoWqA9Qgyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}